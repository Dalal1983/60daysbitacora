{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Por qué?</h3>\n",
    "Han pasado 14 días, y los segundos han corrido cargados de nuevo conocimiento sobre el mundo de machine learning (ML). El 1 de Oct/2018 ha comenzado un periodo de 60 días para aprender y profundizar lo que más se pueda sobre algoritmos y aplicaciones de machine learning. El enfasis es general, pero con un gusto particular de aplicaciones en el campo financiero, más precisamente bursátil y riesgos financieros. Este es uno de los primeros acercamientos al respecto.\n",
    "\n",
    "<h1>Random Forest</h1><h2>Primer acercamiento</h2>\n",
    "He dicho el enfasis particular, razón por la cual en esta ocasión traigo un ejemplo de uno de los primeros algoritmos implementados de ML por mi persona, el ya ampliamente conocido Random Forest. No pretendo explicar el modelo en esta hoja, por el contrario, quiero dar a conocer un ejemplo de aplicación practica, sobre uno de los casos de riesgos, el de default. Para cumplir con este objetivo, tomamos un dataset enviado por una empresa en uno de sus test para el cargo de cientifico de datos junior. El nombre .... por obvias razones no se dirá, pero debo decir que es uno de los dataset encontrados en <a href=\"https://www.kaggle.com/\">Kaggle</a>, la plataforma de juego para cientificos de datos.\n",
    "\n",
    "Ahora sin más, manos a la obra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que haremos, será agrega las lineas en el código python, para soportar UTF-8 (La verdad no recuerdo si más adelante uso caractéres propios de UTF-8, así que serán más por si las mosas.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de esto, importaremos las principales librerias para nuestro ejercicio de esta manera:\n",
    "\n",
    "* __Pandas__ : Para la lectura del archivo csv que contiene nuestros datos\n",
    "\n",
    "* __RandomForestClassifier__ : La clase de SkLearn para el modelado de RandomForest\n",
    "\n",
    "* __train_test_split__ : La clase, también de SkLearn, que nos separa los datos de entrenamiento, de los de prueba\n",
    "\n",
    "* __confusion_matrix__ : Clase de SkLearn, muy util para validar que tan asertivo pudo ser el modelo cuando la variable respuesta es categórica o Discreta (pequeña)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acto seguido, leeremos los datos del archivo llamado Data.csv\n",
    "\n",
    "La descripción de cada una de las columnas, del archivo, pueden verlo en <a href=\"https://www.kaggle.com/dataforyou/bankloan/home\">Kaggle</a>. Para confirmar que ha sido cargado, mostramos las columnas del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customer_ID',\n",
       " 'Status_Checking_Acc',\n",
       " 'Duration_in_Months',\n",
       " 'Credit_History',\n",
       " 'Purposre_Credit_Taken',\n",
       " 'Credit_Amount',\n",
       " 'Savings_Acc',\n",
       " 'Years_At_Present_Employment',\n",
       " 'Inst_Rt_Income',\n",
       " 'Marital_Status_Gender',\n",
       " 'Other_Debtors_Guarantors',\n",
       " 'Current_Address_Yrs',\n",
       " 'Property',\n",
       " 'Age',\n",
       " 'Other_Inst_Plans ',\n",
       " 'Housing',\n",
       " 'Num_CC',\n",
       " 'Job',\n",
       " 'Dependents',\n",
       " 'Telephone',\n",
       " 'Foreign_Worker',\n",
       " 'Default_On_Payment']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../../data_source/Data.csv'\n",
    "data = pd.read_csv(file_path, sep=';')\n",
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ebemos establecer del conjunto completo de datos, cuantos corresponden a entrenamiento y cuandos a pruebas. Para el ejercicio tomamos 3000 para entrenamiento y el restante para pruebas. Para llevar a cabo esta tarea, usaremos train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, train_size =3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este modo, han quedado guardados en **data_train**, los datos para entrenamiento y en **data_test** los datos de prueba. Antes de conituar, es necesario validar la estructura del dataframe de datos para entrenamiento y prueba. Esto se realiza con el fin de validar si alguna de las columnas requiera ser transformada a un valor numérico, pues las clases de SkLearn, suelen tener como entrada matrices numéricas. Para el caso de columnas con valores categóricos, se lleva a cabo una transformación a su código numérico, donde la magnitud del mismo no respresenta ordenamiento alguno entre los valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID                     int64\n",
       "Status_Checking_Acc            object\n",
       "Duration_in_Months              int64\n",
       "Credit_History                 object\n",
       "Purposre_Credit_Taken          object\n",
       "Credit_Amount                   int64\n",
       "Savings_Acc                    object\n",
       "Years_At_Present_Employment    object\n",
       "Inst_Rt_Income                  int64\n",
       "Marital_Status_Gender          object\n",
       "Other_Debtors_Guarantors       object\n",
       "Current_Address_Yrs             int64\n",
       "Property                       object\n",
       "Age                             int64\n",
       "Other_Inst_Plans               object\n",
       "Housing                        object\n",
       "Num_CC                          int64\n",
       "Job                            object\n",
       "Dependents                      int64\n",
       "Telephone                      object\n",
       "Foreign_Worker                 object\n",
       "Default_On_Payment              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['Status_Checking_Acc']           = data_train['Status_Checking_Acc'].astype('category').cat.codes        \n",
    "data_train['Credit_History']                = data_train['Credit_History'].astype('category').cat.codes               \n",
    "data_train['Purposre_Credit_Taken']         = data_train['Purposre_Credit_Taken'].astype('category').cat.codes        \n",
    "data_train['Savings_Acc']                   = data_train['Savings_Acc'].astype('category').cat.codes                  \n",
    "data_train['Years_At_Present_Employment']   = data_train['Years_At_Present_Employment'].astype('category').cat.codes  \n",
    "data_train['Marital_Status_Gender']         = data_train['Marital_Status_Gender'].astype('category').cat.codes        \n",
    "data_train['Other_Debtors_Guarantors']      = data_train['Other_Debtors_Guarantors'].astype('category').cat.codes\n",
    "data_train['Property']                      = data_train['Property'].astype('category').cat.codes\n",
    "data_train['Other_Inst_Plans ']             = data_train['Other_Inst_Plans '].astype('category').cat.codes             \n",
    "data_train['Housing']                       = data_train['Housing'].astype('category').cat.codes \n",
    "data_train['Job']                           = data_train['Job'].astype('category').cat.codes            \n",
    "data_train['Telephone']                     = data_train['Telephone'].astype('category').cat.codes                \n",
    "data_train['Foreign_Worker']                = data_train['Foreign_Worker'].astype('category').cat.codes                   \n",
    "\n",
    "data_test['Status_Checking_Acc']           = data_test['Status_Checking_Acc'].astype('category').cat.codes        \n",
    "data_test['Credit_History']                = data_test['Credit_History'].astype('category').cat.codes               \n",
    "data_test['Purposre_Credit_Taken']         = data_test['Purposre_Credit_Taken'].astype('category').cat.codes        \n",
    "data_test['Savings_Acc']                   = data_test['Savings_Acc'].astype('category').cat.codes                  \n",
    "data_test['Years_At_Present_Employment']   = data_test['Years_At_Present_Employment'].astype('category').cat.codes  \n",
    "data_test['Marital_Status_Gender']         = data_test['Marital_Status_Gender'].astype('category').cat.codes        \n",
    "data_test['Other_Debtors_Guarantors']      = data_test['Other_Debtors_Guarantors'].astype('category').cat.codes\n",
    "data_test['Property']                      = data_test['Property'].astype('category').cat.codes\n",
    "data_test['Other_Inst_Plans ']             = data_test['Other_Inst_Plans '].astype('category').cat.codes             \n",
    "data_test['Housing']                       = data_test['Housing'].astype('category').cat.codes \n",
    "data_test['Job']                           = data_test['Job'].astype('category').cat.codes            \n",
    "data_test['Telephone']                     = data_test['Telephone'].astype('category').cat.codes                \n",
    "data_test['Foreign_Worker']                = data_test['Foreign_Worker'].astype('category').cat.codes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID                    int64\n",
       "Status_Checking_Acc             int8\n",
       "Duration_in_Months             int64\n",
       "Credit_History                  int8\n",
       "Purposre_Credit_Taken           int8\n",
       "Credit_Amount                  int64\n",
       "Savings_Acc                     int8\n",
       "Years_At_Present_Employment     int8\n",
       "Inst_Rt_Income                 int64\n",
       "Marital_Status_Gender           int8\n",
       "Other_Debtors_Guarantors        int8\n",
       "Current_Address_Yrs            int64\n",
       "Property                        int8\n",
       "Age                            int64\n",
       "Other_Inst_Plans                int8\n",
       "Housing                         int8\n",
       "Num_CC                         int64\n",
       "Job                             int8\n",
       "Dependents                     int64\n",
       "Telephone                       int8\n",
       "Foreign_Worker                  int8\n",
       "Default_On_Payment             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya convertidos los datos, a valores numéricos, lo que se hará será parametrizar modelos _random forest_. Se decide hacer la parametrización de tres, debido a que la librería soporta tres tipos diferentes de criterio para el _split_ de las caracteristicas de los árboles. Para conocer más a fondo estos criterios, y otros más, puede consultar <a href=\"http://www.ise.bgu.ac.il/faculty/liorr/hbchap9.pdf\">Decision Tree</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classificator_gini = RandomForestClassifier(n_estimators=1000, random_state=0, criterion='gini')\n",
    "model_classificator_entropy = RandomForestClassifier(n_estimators=1000, random_state=0, criterion='entropy')\n",
    "model_classificator_none = RandomForestClassifier(n_estimators=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante resaltar que uno de los parámetros más importantes es **n_estimators**, pues define la cantidad de árboles que se usaran en el algoritmo para clasificar los valores de los datos de entrenamiento. Como ya resulta evidente, en los tres modelos se implementan 1000. Como se mencionó anteriormente, varios de los algoritmos en SkLearn, admite los datos en forma de matriz, razón por la cual se crea la variable **data_train_Array**, como matriz pura de **data_train**, y posteriormente se dice a cada uno de los modelos, que calcule los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_Array = data_train.as_matrix()\n",
    "model_classificator_gini.fit(data_train_Array[:,0:21], data_train_Array[:,21])\n",
    "model_classificator_entropy.fit(data_train_Array[:,0:21], data_train_Array[:,21])\n",
    "model_classificator_none.fit(data_train_Array[:,0:21], data_train_Array[:,21])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora la parte más emocionante de todo esto, los resultados. Estos se muestran por medio de sus matrices de confusión, entendiendo cada intersección de filas y columnas, como los valores reales de los datos de prueba, y los valores pronosticados para los mismos, según cada uno de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ========================================== GINI\n",
      "[[1428    0]\n",
      " [   0  572]]\n",
      " ========================================== ENTROPY\n",
      "[[1428    0]\n",
      " [   0  572]]\n",
      " ========================================== NONE\n",
      "[[1428    0]\n",
      " [   0  572]]\n"
     ]
    }
   ],
   "source": [
    "data_test_Array = data_test.as_matrix()\n",
    "\n",
    "y_predict = model_classificator_gini.predict(data_test_Array[:,0:21])\n",
    "confu_matrix = confusion_matrix(data_test_Array[:,21], y_predict)\n",
    "print(' ========================================== GINI')\n",
    "print(confu_matrix)\n",
    "\n",
    "y_predict = model_classificator_entropy.predict(data_test_Array[:,0:21])\n",
    "confu_matrix = confusion_matrix(data_test_Array[:,21], y_predict)\n",
    "print(' ========================================== ENTROPY')\n",
    "print(confu_matrix)\n",
    "\n",
    "y_predict = model_classificator_none.predict(data_test_Array[:,0:21])\n",
    "confu_matrix = confusion_matrix(data_test_Array[:,21], y_predict)\n",
    "print(' ========================================== NONE')\n",
    "print(confu_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender estas matrices, debe señalarse que la primer columna, son los valores pronosticados con riesgo de default 0, mientras la segunda los valores pronosticados con riesgo default 1. Por su parte las filas, serán los valores reales observados de riesgo default 0 y 1 respectivamente. Dicho esto, para el ejemplo del modelo con criterio de decisión **Gini**, veremos que la cantidad de aciertos entre el pronóstico y los datos observados de riesgo default 0, son de 1390, mientras que los acertados entre el modelo y los observados para riesgo default 1 son 572. Pero los desaciertos de riesgo default 0 son de 33 y los de riesgo default 1, 5. Ante estos hechos, puede ser valido el afirmar que el modelo GINI es capaz de acertar en un casi 97% para riesgos de default 0, mientras que acierta en un valor aproximado de 99% el riesgo de default 1. Esto alentaría a los investigadores para optar por este modelo cuando tienen los datos de los clientes señalados en el archivo de pruebas. Sin embargo cabe resaltar que este modelo puede ser útil para un conjunto de datos con distribuciones similares a las de los datos de prueba, mientras que puede desviar su efectividad si siguen otro patrón.\n",
    "\n",
    "Ahora, es interesante ver como el modelo que mejor se adaptó por su número de errores de pronóstico fue Entropy, el cual sigue el criterio de decisión llamado \"information gain\", como se detalla en la descripción tecnica de la clase en <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">SkLearn</a>. Las razones siguen siendo parte de estos 60 días, así que decirles cualquier razón sería un poco necio de mi parte.\n",
    "\n",
    "Este es todo el todo por ahora. Hasta una próxima entrada.\n",
    "\n",
    "C.Q."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
